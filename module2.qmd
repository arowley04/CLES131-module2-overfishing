---
title: "Module 2: Overfishing"
format: pdf
editor: source
editor_options: 
  chunk_output_type: console
---

```{r}
#| warning: false
library(tidyverse)
```


### Use of GitHub

Link to your forked GH repository:https://github.com/arowley04/CLES131-module2-overfishing

### Use of Quarto

Link to your .qmd file:https://github.com/arowley04/CLES131-module2-overfishing/blob/main/module2.qmd

## Overexploitation of global fisheries

We will examine the state of global fisheries and seek to reproduce one of the most widely cited examples of species collapse in order to examine the evidence behind an influential paper on global fisheries, [Worm et al. 2006](https://doi.org/10.1126/science.1132294). However, rather than using the 1950-2003 dataset available to Worm and colleagues in 2006, we will be drawing from more recent stock assessment data to see how the trends have fared, specifically in Atlantic cod.

We also explore how to understand and manipulate tabular data using relational database concepts. Instead of working with a single independent dataframe, as in Module 1, we will be working with a large relational database consisting of tables of different dimensions, but are related through one or more IDs.

## The Database

We will use data from the [RAM Legacy Stock Assessment Database](https://www.ramlegacy.org/database/). Note that the database files are available through Zenodo; please download and unzip the file, moving the .RData file only into your own `data/` folder within this project.

Use the code below to load up the tables in this database.

```{r}
load("data/DBdata_asmt_v4.66_.RData")
```

The above function loads all 60 tables of this database, which is a lot! So step one of the data science process is exploring the structure of the database and figuring out how the tables are related.

A selected set of documentation have been provided in `documentation/`. Open up the Database Quickstart Guide for reference as you work through the problems below.

### Q1 (1 point)

One of the main metadata tables is 'stock':

-   How many stocks are there and how many species do they represent?
There are 1514 individual stocks, and they represent 398 different species. 
```{r}
# number of stocks (rows)
nrow(stock)

# number of species
n_distinct(stock$scientificname)
```

-   What are the top three most common stocks? (Okay to use common names; these are standardized for fish)
1. Pink salmon n = 170
2. Sockeye salmon n = 104
3. Chum salmon n = 99
```{r}
# Found 2 diff ways to get the same conclusion

stock |> 
  count(commonname, sort = TRUE) |> 
  arrange(desc(n = 3)) #get n for every species aranged in descending order

stock |> 
  count(commonname, sort = TRUE) |> 
  slice_head(n = 3) #get top 3 n for speciees arranged in descending order
```

-   In your own words, describe the unit of observation in the 'stock' table and some associated variables that describe it.
The unit of observation in the 'stock table' is a fish stock, which is a population of a species within a specific geographic region that is managed as one unit typically relating to fisheries. Associated variables that describe each stock include: scientific/common name of fish stock, stock ID, geographic region (areaid) where the stock is found, and the assessment ID(s) used for monitoring fish stock, and state (currrent state of the fish stock).

### Q2 (1 point)

The next main metadata table is 'assessment':

-   What is the unit of observation in the 'assessment' table? How is this related to the unit of observation in the 'stock' table?
stock = one row per stock (e.g., “Pacific cod – Gulf of Alaska”).
assessment = one row per assessment of that stock (e.g., “assessment of Pacific cod – Gulf of Alaska in 2018 using X model”).

-   It seems like 'stockid' and 'assessyear' might uniquely identify each assessment. Is this the case? If not, why not?
'stockid' and 'assessyear' do not uniquely identify each assessment. There are duplicates of multiple assessments for both. This is likely because some stocks were assessed multiple times in one year, hence 'assessyear' is not unique to 'stockid'. This also explains the need for an 'assessid' variable, which uniquely identifies eeach assessment.
```{r}
# unique variables
assessment |> 
  count(stockid, assessyear) |> 
  filter(n > 1)

# unique stockid
assessment |> 
  count(stockid) |> 
  filter(n > 1)

# unique assessyear
assessment |> 
  count(assessyear) |> 
  filter(n > 1)

# unique assessid
assessment |> 
  count(assessid) |> 
  filter(n > 1)
```

-   Which variable(s) might you use to join 'stock' and 'assessment'?
I would join stockid because both 'stock' and 'assessment' have this variable and it is unique, which allows it to be easily joined.
```{r}
# Join stock to assessments
stock_assess <- stock %>%
  left_join(assessment, by = "stockid")
View(stock_assess)
```


### Q3 (1 point)

In section B of the Database Quick Guide, additional metadata tables are listed in section B. With your data exploration skills, complete the following table:

| B table      | Associated table | join column from B | join column from other |
| ------------ | ---------------- | ------------------ | ---------------------- |
| area         | stock            | areaid             | areaid                 |
| assessmethod | assessment       | assessmethodid     | assessmethodid         |
| assessor     | assessment       | assessorid         | assessorid             |
| management   | stock            | mgmt               | mgmt                   |
| taxonomy     | stock            | tsn                | tsn                    |

\*Note that assessmethod is not a data.frame, which was perhaps an oversight; consider turning it into one for the ease of using tidyverse functions.

```{r}
# convert assessmethd into data.frame

assessmethod_df <- as_tibble(assessmethod)
View(assessmethod_df)
```

```{r}
## Identify primary keys

# area
area |> 
  count(areaid) |> 
  filter(n > 1)

# asessmethod
assessmethod_df |> 
  count(methodlong) |> 
  filter(n > 1)

assessmethod_df |> 
  count(methodshort) |> 
  filter(n > 1)

# assesor
assessor |> 
  count(assessorid) |> 
  filter(n > 1)

# management
management |> 
  count(mgmt) |> 
  filter(n > 1)

# taxonomy
taxonomy |> 
  count(tsn) |> 
  filter(n > 1)
```

```{r}
## Identify foreign keys 

# area -> stock
intersect(colnames(area), 
          colnames(stock)) #should show "areaid"

# management -> stock
intersect(colnames(management), 
          colnames(stock)) #should show "mgmt"

# taxonomy -> stock
intersect(colnames(taxonomy),
          colnames(stock)) #should show "taxonid"

# assessmethod -> assessment 
intersect(colnames(assessmethod), 
          colnames(assessment)) #should show "assessmethodid"

# assessor -> assessment
intersect(colnames(assessor), 
          colnames(assessment)) #should show "assessorid"
```

```{r}
# Exploratory join: add area metadata to stock
stock %>%
  left_join(area, 
            by = "areaid") |> 
  glimpse()

# Exploratory join: add assessor info to assessment
assessment %>%
  left_join(assessor, 
            by = "assessorid") |> 
  glimpse()
```


### Q4 (1 point)

There are two main data tables described in section C, but their key attributes are difficult to understand. Join the two main data tables with their respective metrics tables (section D):

```{r}
# Join timeseries with tsmetrics
ts_with_metrics <- timeseries |> 
  left_join(tsmetrics, 
            by = c("tsid" = "tsunique"))
ts_with_metrics

# Join bioparams with biometrics
bio_with_metrics <- bioparams |> 
  left_join(biometrics, 
            by = c("bioid" = "biounique"))
bio_with_metrics   
```

-   Briefly describe the contents of each joined table.
Combining the timeseries and tsmetrics into a new dataset,"ts_with_metrics", joins the variables tsid (unique time series ID), tsyear (year of the observation), tsvalue (value of the metric ie.catch, exploitation rate, etc.), stockid (stock code), stocklong (full stock name), tscategory / tsshort / tslong (type and description of the time series), and tsunitsshort / tsunitslong (units of measurement) from the timeseries dataset with the assessid (ID for the stock assessment) variable from the tsmetrics dataset.

Combining the bioparms and biometrics into a new dataset, "bio_with_metrics", joins the variables bioid (unique ID for the biological parameter e.g., growth rate, natural mortality), stockid (short stock code), stocklong (full stock name), and bioparam / biounit (type of biological parameter and its units), with the metadata and assessid (stock assessment ID linked to the parameter) from the biomeetrics dataset.

-   What is accomplished by joining these tables?
Each row in ts_with_metrics has one observation for one stock in one year and has extra metadata from tsmetrics included.

Each row in bio_with_metrics has one biological parameter for one stock and has extra metadata from the biometrics table.

## Overexploitation of Atlantic cod

This database is clearly complex and contains a lot of information. We've grappled with its high dimensionality by exploring and joining tables above. Next, we will take a "bottom-up" approach and evaluate a single species, Atlantic cod. Read this [book chapter](https://pressbooks.pub/extinctionstories/chapter/atlantic-cod/) on Atlantic cod, which serves as a reference for the following questions.

### Q5 (1 point)

The collapse of the Atlantic cod fisheries is well documented. Let's see if we can visualize that decline with this database. 

-   How many unique fish stocks comprise "Atlantic cod" and what regions do they come from?
There are 28 unique Altantic cod fish stocks within the database. They come from 4 regions: Canada East Coast, Europe non EU, European Union, and US East Coast. 
 
```{r}
stock %>%
  filter(commonname == "Atlantic cod") |>  #filtering for only Atlantic cod
  distinct(stockid, 
           region) |> #specifying unique stocks within Atlantic cod by region
  summarise(
    n_stocks = n_distinct(stockid), #finding number of distinct Altantic cod stocks by region
    regions = paste(unique(region), 
                    collapse = ", ")
  )
```

Create a vector of the 'stockid' associated with "Atlantic cod". Then turn your attention to the previously-joined timeseries/tsmetrics table and create a subsetted dataframe with only observations of "Atlantic cod" that have a non-NA value. This table reports many years and many metrics, while we are primarily interested in the years since 1950.

-   Which metrics are most commonly reported for Atlantic cod in this timeframe and what do they mean?
The top reported metrics are: 
- Catch / Total Landings - how much cod was taken from the ocean (exploitation).
- Spawning Stock Biomass (SSB) -the total weight of fish capable of reproducing — a key indicator of stock health.
- Recruits - young fish entering the population, crucial for recovery.
- Fishing mortality (F) - the intensity of fishing pressure relative to stock size.

```{r}
# Create a vector of the 'stockid' associated with "Atlantic cod"
atlantic_stockid <- stock |> 
  filter(commonname == "Atlantic cod") |>  #filtering for only Atlantic cod
  pull(stockid)   #creates vector of stock IDs
atlantic_stockid
```

```{r}
# Create a subsetted dataframe with only observations of "Atlantic cod" that have a non-NA value
# View(ts_with_metrics)

cod_ts_with_metrics <- ts_with_metrics |> 
  filter(stockid %in% atlantic_stockid, 
         !is.na(tsvalue), 
         tsyear >= 1950) |> 
  count(tslong, sort = TRUE)
cod_ts_with_metrics
```


### Q6 (1 point)

Make a timeseries figure for each stock of Atlantic cod. Rather than coloring by the identity of the stock, color by the region it comes from (this may require joining). Use `facet_*()` to plot both metrics in a single code chunk. Connect the points for each stock and focus on the period since 1950. Update until the figure is easily interpretable.

-   What happened to Atlantic cod stocks during the period 1950-present? What information does each metric convey?

Total landings (catch):
Shows human harvest. In many stocks, catches increased until the late 1960s–1980s. After that, the stocks collapsed sharply as overfishing outpaced reproduction.

Spawning Stock Biomass (SSB):
Shows reproductive population size. Declines mirror or lag the landings collapse. In Canada East Coast, SSB dropped to historic lows by the early 1990s.
```{r}
cod_metrics <- c("Total landings", 
                 "Spawning Stock Biomass")

cod_ts_plot <- ts_with_metrics |> 
  filter(stockid %in% atlantic_stockid, #filter for 
         !is.na(tsvalue),
         tsyear >= 1950,
         tslong %in% cod_metrics) |> 
  left_join(stock |> 
              select(stockid, region), 
            by = "stockid")
cod_ts_plot
```

```{r}
library(ggplot2)

ggplot(cod_ts_plot, aes(x = tsyear, y = tsvalue, 
                        group = stockid, color = region)) +
  geom_line() +
  facet_wrap(~ tslong, scales = "free_y") +
  theme_minimal() +
  labs(
    title = "Atlantic Cod Stocks Since 1950",
    x = "Year",
    y = "Value",
    color = "Region"
  )
```


### Q7 (1 point)

We will recreate a slightly more complex version of a figure from the [Millennium Ecosystem Assessment](https://www.millenniumassessment.org/documents/document.356.aspx.pdf) (Fig. 11).

Selecting a metric that can be added across stocks, calculate the total fish landings for each region of Atlantic cod. Make a plot similar to Fig. 11 and color by region.
```{r}
cod_landings_region <- cod_ts_plot |> 
  filter(tslong == "Total landings", #filtering for total landings
         tsyear >= 1950) |> 
  group_by(region, tsyear) |> 
  summarise(total_landings = sum(tsvalue, 
                                 na.rm = TRUE), 
            .groups = "drop")
cod_landings_region
```

```{r}
# Plot like Millennium Ecosystem Assessment (Fig. 11 inspo)
ggplot(cod_landings_region, aes(x = tsyear, 
                                y = total_landings, 
                                fill = region)) +
  geom_area(alpha = 0.8, 
            linewidth = 0.2, 
            color = "black") +
  labs(x = "Year",
       y = "Total Landings (MT)",
       fill = "Region") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

```

Which region does Fig. 11 from the MEA correspond to?
Fig. 11 of the Millennium Ecosystem Assessment (MEA) shows the collapse of the Northwest Atlantic cod fishery. This corresponds to the Canada East Coast region in my database.

### Q8 (1 point)

Under the Management Policies section of the [book chapter](https://pressbooks.pub/extinctionstories/chapter/atlantic-cod/), the authors summarize a few major efforts to restore and protect stocks of Atlantic cod. Focusing only on the US and Canada, update your plot from above to include vertical lines to represent the timing of least three major events and label them clearly on your plot. Doing so will likely involve creating a separate dataframe and using it in one of your ggplot layers (one possible argument within `aes()` is `linetype`). Facet the plot by region and update until it is easily interpretable.
```{r}
# Key events dataframe
events <- tibble::tibble(
  event_year = c(1977, 1992, 2003),
  event_label = c("200-mile EEZ", "Canada Cod Moratorium", "US Recovery Plan")
)
events
```

```{r}
ggplot(
  cod_landings_region |>  
    filter(region %in% c("Canada East Coast", 
                         "US East Coast")), 
  aes(x = tsyear, 
      y = total_landings, 
      color = region)
) +
  geom_line(linewidth = 1) + #adding vertical lines for events
  geom_vline(
    data = events,
    aes(xintercept = event_year, linetype = event_label),
    color = "black"
  ) +
  labs(
    x = "Year",
    y = "Total Landings (MT)",
    color = "Region",
    linetype = "Policy Event",
  ) +
  facet_wrap(~region, scales = "free_y") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "bottom")

```

### Q9 (2 points)

What happened to Atlantic cod stocks for each region following each piece of legislation or management plan, and why do you think this was so? Your multi-paragraph answer should be informed by content from the book chapter; additional sources are optional, and all sources should be cited.

The 1977 establishment of Exclusive Economic Zones (EEZs) gave Canada and the U.S. control over coastal waters (200 nautical miles offshore). This was intended to reduce foreign fishing. However, domestic fleets rapidly expanded, and due to lack of strong fishing regulations/limits, overfishing got worse. Essentially, instead of protecting stocks, EEZs accelerated their decline (Extinction Stories, “Atlantic Cod”).

Canada’s 1992 cod moratorium was one of the most significant events that shut down most commercial fishing after stocks collapsed. Despite landings decreasing to almost zero, cod did not recover as expected. The chapter explains that ecological shifts, such as increases in forage fish and invertebrates, altered the balance of the ecosystem, which hindered cod rebound even though there was lower fishing pressure.

US recovey plans like the 2003 Magnuson-Stevens Act were created to rebuild cod stocks in the Georges Bank and the Gulf of Maine. Although stricter regulations were established, populations remained low due to slow cod reproduction, enforcement challenges, and climate-driven changes in the North Atlantic.

The chapter highlights the importance of regulatory policies before the damage is done. Even though major policies were implemented, they came too late to make significant improvements once the damage was done. Once cod stocks collapsed, ecological feedbacks and environmental stressors prevented large-scale recovery. The Atlantic cod story is a good example of how difficult it is to truly reverse ecosystem collapses and highlights the importance of precautionary fisheries management (Extinction Stories, “Atlantic Cod”).

Works cited:
Extinction Stories. Atlantic Cod. Pressbooks, https://pressbooks.pub/extinctionstories/chapter/atlantic-cod/
.